{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Excalibur\\\\Desktop\\\\VERİ BİLİMİ\\\\Makine Öğrenmesi\\\\verisetleri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KullaniciID</th>\n",
       "      <th>Cinsiyet</th>\n",
       "      <th>Yas</th>\n",
       "      <th>TahminiMaas</th>\n",
       "      <th>SatinAldiMi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Kadın</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Kadın</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Erkek</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KullaniciID Cinsiyet  Yas  TahminiMaas  SatinAldiMi\n",
       "0     15624510    Erkek   19        19000            0\n",
       "1     15810944    Erkek   35        20000            0\n",
       "2     15668575    Kadın   26        43000            0\n",
       "3     15603246    Kadın   27        57000            0\n",
       "4     15804002    Erkek   19        76000            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"SosyalMedayReklamKampanyası.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veriyi Anlamak\n",
    "Yukarıda gördüğümüz **veri seti beş nitelikten oluşuyor**. Veri seti bir sosyal medya kayıtlarından derlenmiş durumda. KullaniciID müşteriyi belirleyen eşsiz rakam, Cinsiyet, Yaş, Tahmini Gelir yıllık tahmin edilen gelir, SatinAldiMi ise belirli bir ürünü satın almış olup olmadığı, hadi lüks araba diyelim. Bu veri setinde kolayca anlaşılabileceği gibi **hedef değişkenimiz SatinAldiMi**’dir. **Diğer dört nitelik ise bağımsız niteliklerdir**. Bu bağımsız niteliklerle bağımlı nitelik (satın alma davranışının gerçekleşip gerçekleşmeyeceği) tahmin edilecek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Veri Setini Bağımlı ve Bağımsız Niteliklere Ayırmak**\n",
    "\n",
    "Yukarıda gördüğümüz niteliklerden bağımsız değişken olarak sadece **yaş** ve **tahmini maaşı** kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "395    1\n",
       "396    1\n",
       "397    1\n",
       "398    0\n",
       "399    1\n",
       "Name: SatinAldiMi, Length: 400, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"Yas\", \"TahminiMaas\"]]\n",
    "y = data.SatinAldiMi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veriyi Eğitim ve Test Olarak Ayırmak\n",
    "Veri setinde 400 kayıt var bunun 300’ünü eğitim, 100’ünü test için ayıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# eğitim ve test verilerini ayırmak için kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "Bağımsız değişkenlerden yaş ile tahmini gelir aynı birimde olmadığı için feature scaling uygulayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Standardizasyon**, ortalama değerin 0, standart sapmanın ise 1 değerini aldığı, dağılımın normale yaklaştığı bir metoddur. \n",
    "\n",
    "Formülü şu şekildedir, elimizdeki değerden ortalama değeri çıkartıyoruz, sonrasında varyans değerine bölüyoruz.\n",
    "\n",
    ">   **(X - u) / s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada **fit** metodu, eğitim veri setine uygulandığında, model parametrelerini öğrenir (örneğin, ortalama ve standart sapma). Daha sonra , dönüştürülmüş (ölçeklendirilmiş) eğitim veri setini elde etmek için **transform** (dönüşüm) yöntemini eğitim veri setine uygulamamız gerekir. \"Dönüştürme\" , verileri otomatik olarak ölçeklendirmek için önceden hesaplanmış bir ortalama ve std kullanır (tüm değerlerden ortalamayı çıkarın ve sonra std'ye bölün). Eğitim veri setinde **fit_transform** uygulayarak bu adımların her ikisini de bir adımda gerçekleştirebiliriz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K En Yakın Komşu Modeli Oluşturmak ve Eğitmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **n_neighbors** kullanılacak komşu sayısı. \n",
    "* **metric** komşuların yakınlığını belirlemede hangi yöntemi kullanacağımızı belirler. **Mesafeye dayalı** yöntem kullanacak isek **minkowski** seçiyoruz. \n",
    "* **p** ise hangi mesafe yöntemini k kullanacağımız, 2 **öklid** mesafesini kullan demektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Seti ile Tahmin Yapmak\n",
    "Ayırdığımız test setimizi (X_test) kullanarak oluşturduğumuz model ile tahmin yapalım  ve elde ettiğimiz set (y_pred) ile hedef değişken (y_test) test setimizi karşılaştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test) # Tahmin işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerçek : \n",
      "\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]\n",
      "\n",
      "\n",
      "Tahmin :\n",
      "\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# gerçek değerle tahmini gözlemleyelim. Biz ne yaptık anlayalım...\n",
    "print(\"Gerçek : \\n\\n\", y_test.values)\n",
    "print(\"\\n\\nTahmin :\\n\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 13\\. indexde bulunan müşteriye baktığımızda gerçekte satın alma gerçekleşmemişken model satın alır demiş, yani yanlış sınıflandırma yapmış. Şimdi kaç tane doğru kaç tane yanlış sınıflandırma olmuş bir bakalım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hata Matrisini Oluşturma\n",
    "Yaptığımız sınıflandırmanın doğruluğunu kontrol etme yöntemlerinden birisi de hata matrisi oluşturmaktır. \n",
    "* Hata matrisi için scikit-learn kütüphanesi **metrics** modülü **confusion_matrix** fonksiyonunu kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59,  9],\n",
       "       [ 8, 24]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 kayıtlık test verisi ayırmıştık. Yukarıda gördüğümüz hata matrisine göre 17 kayıt yanlış sınıflandırılmış, 83 kayıt doğru sınıflandırılmış. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
